{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_and_shuffle_labels(y_data, seed):\n",
    "    num_of_class = len(set(y_data.tolist()))\n",
    "    y_data=pd.DataFrame(y_data, columns=['label'])\n",
    "    y_data['index'] = np.arange(len(y_data))\n",
    "    label_dict = dict()\n",
    "    cur_idx = list()\n",
    "\n",
    "    for i in range(num_of_class):\n",
    "        var_name = 'label' + str(i)\n",
    "        label_info = y_data[y_data['label'] == i]\n",
    "        np.random.seed(seed)\n",
    "        label_info = np.random.permutation(label_info)\n",
    "        label_info = pd.DataFrame(label_info, columns=['label', 'index'])\n",
    "        label_dict.update({var_name: label_info })\n",
    "        cur_idx.append(0)\n",
    "\n",
    "    return label_dict, cur_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_iid_subsamples_indices(y_data, number_of_samples, seed):\n",
    "    num_of_class = len(set(y_data.tolist()))\n",
    "    label_dict, cur_idx = _split_and_shuffle_labels(y_data, seed)\n",
    "    sample_dict = dict()\n",
    "    dist = 1.0 / num_of_class\n",
    "    for i in range(number_of_samples):\n",
    "        sample_name = 'sample' + str(i)\n",
    "        dumb = pd.DataFrame()\n",
    "        for j in range(num_of_class):\n",
    "            label_name = str('label') + str(j)\n",
    "            if i == (number_of_samples - 1):\n",
    "                next_idx = len(label_dict[label_name])\n",
    "            else:\n",
    "                next_idx = int(len(label_dict[label_name]) * dist)\n",
    "                next_idx += cur_idx[j]\n",
    "            temp = label_dict[label_name][cur_idx[j]:next_idx]\n",
    "            dumb=pd.concat([dumb, temp], axis=0)\n",
    "            cur_idx[j] = next_idx\n",
    "        dumb.reset_index(drop=True, inplace=True)    \n",
    "        sample_dict.update({sample_name: dumb}) \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_non_iid_subsamples_indices(y_data, number_of_samples, pdist, seed):    \n",
    "    num_of_class = len(set(y_data.tolist()))\n",
    "    label_dict, cur_idx = _split_and_shuffle_labels(y_data, seed)\n",
    "    sample_dict = dict()\n",
    "    for i in range(number_of_samples):\n",
    "        sample_name = 'sample' + str(i)\n",
    "        dumb = pd.DataFrame()\n",
    "        dist1 = pdist * (2 / 3)\n",
    "        dist2 = pdist - dist1\n",
    "        dist3 = (1.0 - pdist) / (num_of_class - 2)\n",
    "        for j in range(num_of_class):\n",
    "            label_name = str('label') + str(j)\n",
    "            dist = dist1 if j == i else dist2 if (j % 5) == (i % 5) else dist3\n",
    "            if i == (number_of_samples - 1):\n",
    "                next_idx = len(label_dict[label_name])\n",
    "            else:\n",
    "                next_idx = int(len(label_dict[label_name]) * dist)\n",
    "                next_idx += cur_idx[j]\n",
    "            temp = label_dict[label_name][cur_idx[j]:next_idx]\n",
    "            dumb = pd.concat([dumb, temp], axis=0)\n",
    "            cur_idx[j] = next_idx\n",
    "        dumb.reset_index(drop=True, inplace=True)    \n",
    "        sample_dict.update({sample_name: dumb}) \n",
    "    return sample_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_subsamples(sample_dict, x_data, y_data, x_name, y_name):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        indices=np.sort(np.array(sample_dict[sample_name]['index']))\n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_corrupted_subsamples(sample_dict, x_data, y_data, x_name, y_name,\n",
    "                                 cor_local_ratio=1.0, cor_label_ratio=0.2, cor_data_ratio=0.5, mode=1):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "    \n",
    "    # make corrupted info\n",
    "    num_of_local = len(sample_dict)\n",
    "    num_of_label = len(set(y_data.tolist()))\n",
    "    cor_local_idx = random.sample(range(0, num_of_local), int(num_of_local * cor_local_ratio))\n",
    "    cor_label_idx = random.sample(range(0, num_of_label), int(num_of_label * cor_label_ratio))\n",
    "    temp = set(y_data.tolist())\n",
    "    temp.difference_update(cor_label_idx)\n",
    "    if mode == 1:\n",
    "        temp = list(temp)\n",
    "        cor_vals = random.sample(temp, int(num_of_label * cor_label_ratio))\n",
    "        print(cor_label_idx, '->', cor_vals)\n",
    "    else:\n",
    "        print(cor_label_idx, '-> random value')\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        indices=np.sort(np.array(sample_dict[sample_name]['index']))\n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        \n",
    "        if i in cor_local_idx:\n",
    "            val_cnt = 0\n",
    "            for j in cor_label_idx:\n",
    "                temp_dices = np.where(y_info == j)[0]\n",
    "                cor_data_len = int(len(temp_dices) * cor_data_ratio)\n",
    "                corrupted_idx = random.sample(list(temp_dices), cor_data_len)\n",
    "                \n",
    "                if mode == 1:\n",
    "                    y_info[corrupted_idx] = cor_vals[val_cnt]\n",
    "                    val_cnt = val_cnt + 1\n",
    "                else:\n",
    "                    for i in corrupted_idx:\n",
    "                        temp_x = temp\n",
    "                        ori_val = y_info[i].item()\n",
    "                        temp_x.difference_update([ori_val])\n",
    "                        y_info[i] = random.sample(temp_x, 1)[0]\n",
    "    \n",
    "        \n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_corrupted_subsamples2(sample_dict, x_data, y_data, x_name, y_name,\n",
    "                                  cor_local_ratio=1.0, cor_minor_label_cnt=4,\n",
    "                                  cor_major_data_ratio=0.2,\n",
    "                                  cor_minor_data_ratio=0.5,\n",
    "                                  mode=1):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "\n",
    "    # make corrupted info\n",
    "    num_of_local = len(sample_dict)\n",
    "    num_of_label = len(set(y_data.tolist()))\n",
    "    cor_local_idx = random.sample(range(0, num_of_local), int(num_of_local * cor_local_ratio))\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        indices=np.sort(np.array(sample_dict[sample_name]['index']))\n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        \n",
    "        if i in cor_local_idx:\n",
    "            cor_major_label_idx = list()\n",
    "            cor_major_label_idx.append(i)\n",
    "            cor_major_label_idx.append((i+5)%num_of_label)\n",
    "            \n",
    "            for j in cor_major_label_idx:\n",
    "                temp_dices = np.where(y_info == j)[0]\n",
    "                cor_data_len = int(len(temp_dices) * cor_major_data_ratio)\n",
    "                corrupted_idx = random.sample(list(temp_dices), cor_data_len)\n",
    "\n",
    "                ori_val = y_info[corrupted_idx][0]\n",
    "                y_info[corrupted_idx] = (ori_val + 5) % num_of_label\n",
    "        \n",
    "            temp = set(tr_y.tolist())\n",
    "            temp.difference_update(cor_major_label_idx)\n",
    "            cor_minor_label_idx = random.sample(temp, cor_minor_label_cnt)\n",
    "            temp.difference_update(cor_minor_label_idx)\n",
    "            cor_minor_vals = random.sample(temp, cor_minor_label_cnt)\n",
    "            print(cor_major_label_idx, '|', cor_minor_label_idx, '->', cor_minor_vals)\n",
    "        \n",
    "            val_cnt = 0\n",
    "            for j in cor_minor_label_idx:\n",
    "                temp_dices = np.where(y_info == j)[0]\n",
    "                cor_data_len = int(len(temp_dices) * cor_minor_data_ratio)\n",
    "                corrupted_idx = random.sample(list(temp_dices), cor_data_len)\n",
    "                \n",
    "                if mode == 1:\n",
    "                    y_info[corrupted_idx] = cor_minor_vals[val_cnt]\n",
    "                    val_cnt = val_cnt + 1\n",
    "                else:\n",
    "                    cor_minor_vals = list()\n",
    "                    for i in corrupted_idx:\n",
    "                        temp_x = temp\n",
    "                        ori_val = y_info[i].item()\n",
    "                        temp_x.difference_update([ori_val])\n",
    "                        y_info[i] = random.sample(temp_x, 1)[0]\n",
    "        \n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict):\n",
    "    sum = 0\n",
    "    print('[*] Train Dataset (x, y)')\n",
    "    for idx, (x_key, y_key) in enumerate(zip(x_train_dict, y_train_dict)):\n",
    "        sum += len(x_train_dict[x_key])\n",
    "        print('- sample{}: {}, {}'.format(idx, len(x_train_dict[x_key]), len(y_train_dict[y_key])))\n",
    "        print(': ', end='')\n",
    "        for i in range(10):\n",
    "            print(y_train_dict[y_key].tolist().count(i), end=' ')\n",
    "        print('')\n",
    "    print('# total:', sum, end='\\n\\n')\n",
    "\n",
    "    sum = 0\n",
    "    print('[*] Test Dataset (x, y)')\n",
    "    for idx, (x_key, y_key) in enumerate(zip(x_test_dict, y_test_dict)):\n",
    "        sum += len(x_test_dict[x_key])\n",
    "        print('- sample{}: {}, {}'.format(idx, len(x_test_dict[x_key]), len(y_test_dict[y_key])))\n",
    "        print(': ', end='')\n",
    "        for i in range(10):\n",
    "            print(y_test_dict[y_key].tolist().count(i), end=' ')\n",
    "        print('')\n",
    "    print('# total:', sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(path='./data/mnist.pkl.gz', torch_tensor=True):\n",
    "    data_path = Path(path)\n",
    "    with gzip.open(data_path, \"rb\") as f:\n",
    "        ((x_train, y_train), (x_test, y_test)) = pickle.load(f)\n",
    "        \n",
    "    if torch_tensor:\n",
    "        x_train, y_train, x_test, y_test = map(torch.tensor, (x_train, y_train, x_test, y_test))\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_iid_samples(x_train, y_train, x_test, y_test, num_of_sample=10, pdist=0.6, seed=1, verbose=True):\n",
    "    sample_dict_train = _get_non_iid_subsamples_indices(y_train, num_of_sample, pdist, seed)\n",
    "    x_train_dict, y_train_dict = _create_subsamples(sample_dict_train, x_train, y_train, 'x_train', 'y_train')\n",
    "    \n",
    "    sample_dict_test = _get_non_iid_subsamples_indices(y_test, num_of_sample, pdist, seed)\n",
    "    x_test_dict, y_test_dict = _create_subsamples(sample_dict_test, x_test, y_test, 'x_test', 'y_test')\n",
    "    \n",
    "    if verbose:\n",
    "        _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict)\n",
    "    return x_train_dict, y_train_dict, x_test_dict, y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corrupted_non_iid_samples(x_train, y_train, x_test, y_test, \n",
    "                                     cor_local_ratio=1.0,\n",
    "                                     cor_minor_label_cnt=4,\n",
    "                                     cor_major_data_ratio=0.2,\n",
    "                                     cor_minor_data_ratio=0.5, mode=1,\n",
    "                                     num_of_sample=10, pdist=0.6, seed=1, verbose=True):\n",
    "    sample_dict_train = _get_non_iid_subsamples_indices(y_train, num_of_sample, pdist, seed)\n",
    "    x_train_dict, y_train_dict = _create_corrupted_subsamples2(sample_dict_train, x_train, y_train,\n",
    "                                                               'x_train', 'y_train',\n",
    "                                                               cor_local_ratio, cor_minor_label_cnt,\n",
    "                                                               cor_major_data_ratio, cor_minor_data_ratio, mode)\n",
    "    \n",
    "    sample_dict_test = _get_non_iid_subsamples_indices(y_test, num_of_sample, pdist, seed)\n",
    "    x_test_dict, y_test_dict = _create_subsamples(sample_dict_test, x_test, y_test, 'x_test', 'y_test')\n",
    "    \n",
    "    if verbose:\n",
    "        _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict)\n",
    "    return x_train_dict, y_train_dict, x_test_dict, y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iid_samples(x_train, y_train, x_test, y_test, num_of_sample=10, seed=1, verbose=True):\n",
    "    sample_dict_train = _get_iid_subsamples_indices(y_train, num_of_sample, seed)\n",
    "    x_train_dict, y_train_dict = _create_subsamples(sample_dict_train, x_train, y_train, 'x_train', 'y_train')\n",
    "    \n",
    "    sample_dict_test = _get_iid_subsamples_indices(y_test, num_of_sample, seed)\n",
    "    x_test_dict, y_test_dict = _create_subsamples(sample_dict_test, x_test, y_test, 'x_test', 'y_test')\n",
    "    \n",
    "    if verbose:\n",
    "        _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict)\n",
    "    return x_train_dict, y_train_dict, x_test_dict, y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corrupted_iid_samples(x_train, y_train, x_test, y_test,\n",
    "                                 cor_local_ratio=1.0, cor_label_ratio=0.2, cor_data_ratio=0.5, mode=1,\n",
    "                                 num_of_sample=10, seed=1, verbose=True):\n",
    "    sample_dict_train = _get_iid_subsamples_indices(y_train, num_of_sample, seed)\n",
    "    x_train_dict, y_train_dict = _create_corrupted_subsamples(sample_dict_train, x_train, y_train,\n",
    "                                                              'x_train', 'y_train',\n",
    "                                                              cor_local_ratio, cor_label_ratio, cor_data_ratio,\n",
    "                                                              mode)\n",
    "    \n",
    "    sample_dict_test = _get_iid_subsamples_indices(y_test, num_of_sample, seed)\n",
    "    x_test_dict, y_test_dict = _create_subsamples(sample_dict_test, x_test, y_test, 'x_test', 'y_test')\n",
    "    \n",
    "    if verbose:\n",
    "        _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict)\n",
    "    return x_train_dict, y_train_dict, x_test_dict, y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(x_train, y_train, x_test, y_test, batch_size):\n",
    "    train_data = None\n",
    "    test_data = None\n",
    "    \n",
    "    if x_train != None and y_train != None:\n",
    "        train_data = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    if x_test != None and y_test != None:\n",
    "        test_data = DataLoader(TensorDataset(x_test, y_test), batch_size=1)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.Size([60000]) torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "tr_X, tr_y, te_X, te_y = load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6] -> random value\n",
      "[*] Train Dataset (x, y)\n",
      "- sample0: 5996, 5996\n",
      ": 674 337 689 692 655 617 296 716 656 664 \n",
      "- sample1: 5996, 5996\n",
      ": 666 337 677 711 664 622 296 686 657 680 \n",
      "- sample2: 5996, 5996\n",
      ": 661 337 679 695 651 637 296 705 675 660 \n",
      "- sample3: 5996, 5996\n",
      ": 664 337 671 709 648 628 296 716 667 660 \n",
      "- sample4: 5996, 5996\n",
      ": 672 337 656 701 657 618 296 711 671 677 \n",
      "- sample5: 5996, 5996\n",
      ": 677 337 668 695 669 619 296 705 659 671 \n",
      "- sample6: 5996, 5996\n",
      ": 667 337 675 696 671 602 296 714 676 662 \n",
      "- sample7: 5996, 5996\n",
      ": 662 337 685 714 665 616 296 700 659 662 \n",
      "- sample8: 5996, 5996\n",
      ": 667 337 697 674 675 641 296 691 649 669 \n",
      "- sample9: 6036, 6036\n",
      ": 665 338 681 689 670 610 300 716 672 695 \n",
      "# total: 60000\n",
      "\n",
      "[*] Test Dataset (x, y)\n",
      "- sample0: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample1: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample2: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample3: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample4: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample5: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample6: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample7: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample8: 996, 996\n",
      ": 98 113 103 101 98 89 95 102 97 100 \n",
      "- sample9: 1036, 1036\n",
      ": 98 118 105 101 100 91 103 110 101 109 \n",
      "# total: 10000\n"
     ]
    }
   ],
   "source": [
    "tr_X_iid_dict, tr_y_iid_dict, te_X_iid_dict, te_y_iid_dict = create_corrupted_iid_samples(\n",
    "    tr_X, tr_y, te_X, te_y,\n",
    "    cor_local_ratio=1.0, cor_label_ratio=0.2, cor_data_ratio=0.5, mode=2,\n",
    "    num_of_sample=10, seed=1, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5] | [6] -> [3]\n",
      "[1, 6] | [8] -> [0]\n",
      "[2, 7] | [6] -> [3]\n",
      "[3, 8] | [4] -> [0]\n",
      "[4, 9] | [8] -> [7]\n",
      "[5, 0] | [9] -> [2]\n",
      "[6, 1] | [4] -> [7]\n",
      "[7, 2] | [5] -> [6]\n",
      "[8, 3] | [0] -> [6]\n",
      "[9, 4] | [8] -> [7]\n",
      "[*] Train Dataset (x, y)\n",
      "- sample0: 5882, 5882\n",
      ": 2207 337 297 453 292 1246 148 313 292 297 \n",
      "- sample1: 6243, 6243\n",
      ": 442 2501 297 306 292 271 1378 313 146 297 \n",
      "- sample2: 6022, 6022\n",
      ": 296 337 2252 453 292 271 148 1384 292 297 \n",
      "- sample3: 6020, 6020\n",
      ": 442 337 297 2294 146 271 295 313 1328 297 \n",
      "- sample4: 5932, 5932\n",
      ": 296 337 297 306 2200 271 295 459 146 1325 \n",
      "- sample5: 5781, 5781\n",
      ": 1294 337 445 306 292 2058 295 313 292 149 \n",
      "- sample6: 6079, 6079\n",
      ": 296 1457 297 306 146 271 2258 459 292 297 \n",
      "- sample7: 6083, 6083\n",
      ": 296 337 1354 306 292 136 430 2343 292 297 \n",
      "- sample8: 5964, 5964\n",
      ": 148 337 297 1356 292 271 443 313 2210 297 \n",
      "- sample9: 5994, 5994\n",
      ": 298 339 305 311 1317 272 303 463 149 2237 \n",
      "# total: 60000\n",
      "\n",
      "[*] Test Dataset (x, y)\n",
      "- sample0: 971, 971\n",
      ": 391 56 51 50 49 178 47 51 48 50 \n",
      "- sample1: 1036, 1036\n",
      ": 49 453 51 50 49 44 191 51 48 50 \n",
      "- sample2: 1010, 1010\n",
      ": 49 56 412 50 49 44 47 205 48 50 \n",
      "- sample3: 994, 994\n",
      ": 49 56 51 403 49 44 47 51 194 50 \n",
      "- sample4: 989, 989\n",
      ": 49 56 51 50 392 44 47 51 48 201 \n",
      "- sample5: 954, 954\n",
      ": 196 56 51 50 49 356 47 51 48 50 \n",
      "- sample6: 1002, 1002\n",
      ": 49 227 51 50 49 44 383 51 48 50 \n",
      "- sample7: 1010, 1010\n",
      ": 49 56 206 50 49 44 47 411 48 50 \n",
      "- sample8: 988, 988\n",
      ": 49 56 51 202 49 44 47 51 389 50 \n",
      "- sample9: 1046, 1046\n",
      ": 50 63 57 55 198 50 55 55 55 408 \n",
      "# total: 10000\n"
     ]
    }
   ],
   "source": [
    "tr_X_iid_dict, tr_y_iid_dict, te_X_iid_dict, te_y_iid_dict = create_corrupted_non_iid_samples(\n",
    "    tr_X, tr_y, te_X, te_y,\n",
    "    cor_local_ratio=1.0,\n",
    "    cor_minor_label_cnt=1,\n",
    "    cor_major_data_ratio=0.2,\n",
    "    cor_minor_data_ratio=0.5, mode=1,\n",
    "    num_of_sample=10, seed=1, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = torch.IntTensor([1, 2, 3])\n",
    "bbb = torch.IntTensor([2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = list()\n",
    "for i in range(100):\n",
    "    data.append(random.sample([1, 2, 3, 4], 1)[0])\n",
    "data = np.array(data)\n",
    "len(np.where(data==4)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tr_dict = _get_non_iid_subsamples_indices(tr_y, 10, 0.9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5, 0, 0,  ..., 0, 5, 5]), 5784)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_name=\"sample0\"\n",
    "indices=np.sort(np.array(sample_tr_dict[sample_name]['index']))\n",
    "\n",
    "y_info= tr_y[indices]\n",
    "y_info, len(y_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_info= np.array(tr_y[indices].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    3,    7, ..., 5779, 5782, 5783], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_info==5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5]\n",
      "[1, 6]\n",
      "[2, 7]\n",
      "[3, 8]\n",
      "[4, 9]\n",
      "[5, 0]\n",
      "[6, 1]\n",
      "[7, 2]\n",
      "[8, 3]\n",
      "[9, 4]\n"
     ]
    }
   ],
   "source": [
    "cor_local_ratio = 1.0\n",
    "cor_minor_label_cnt = 2\n",
    "cor_major_data_ratio = 0.2\n",
    "cor_minor_data_ratio = 0.5\n",
    "\n",
    "num_of_local = len(sample_tr_dict)\n",
    "num_of_label = len(set(tr_y.tolist()))\n",
    "cor_local_idx = random.sample(range(0, num_of_local), int(num_of_local * cor_local_ratio))\n",
    "\n",
    "for i in range(len(sample_tr_dict)):  ### len(sample_dict)= number of samples\n",
    "#     xname= x_name+str(i)\n",
    "#     yname= y_name+str(i)\n",
    "#     sample_name=\"sample\"+str(i)\n",
    "\n",
    "#     indices=np.sort(np.array(sample_dict[sample_name]['index']))\n",
    "\n",
    "#     x_info= x_data[indices,:]\n",
    "#     x_data_dict.update({xname : x_info})\n",
    "\n",
    "#     y_info= y_data[indices]\n",
    "    if i in cor_local_idx:\n",
    "        cor_major_label_idx = list()\n",
    "        cor_major_label_idx.append(i)\n",
    "        cor_major_label_idx.append((i+5)%num_of_label)\n",
    "        print(cor_major_label_idx)\n",
    "        \n",
    "        for j in cor_major_label_idx:\n",
    "            temp_dices = np.where(y_info == j)[0]\n",
    "            cor_data_len = int(len(temp_dices) * cor_major_data_ratio)\n",
    "            corrupted_idx = random.sample(list(temp_dices), cor_data_len)\n",
    "\n",
    "            ori_val = y_info[corrupted_idx][0]\n",
    "            y_info[corrupted_idx] = (ori_val + 5) % num_of_label\n",
    "        \n",
    "#         cor_minor_label_idx = random.sample(range(0, num_of_label), int(cor_minor_label_cnt))\n",
    "        temp = set(tr_y.tolist())\n",
    "        temp.difference_update(cor_major_label_idx)\n",
    "        cor_minor_label_idx = random.sample(temp, cor_minor_label_cnt)\n",
    "        temp.difference_update(cor_minor_label_idx)\n",
    "        cor_minor_val = random.sample(temp, 1)\n",
    "\n",
    "        val_cnt = 0\n",
    "        for j in cor_minor_label_idx:\n",
    "            temp_dices = np.where(y_info == j)[0]\n",
    "            cor_data_len = int(len(temp_dices) * cor_minor_data_ratio)\n",
    "            corrupted_idx = random.sample(list(temp_dices), cor_data_len)\n",
    "\n",
    "            ori_val = y_info[corrupted_idx][0]\n",
    "            cor_val = (ori_val + 1) % num_of_label\n",
    "            y_info[corrupted_idx] = cor_minor_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 1, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 7, 8, 9]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "aaa = set(aaa)\n",
    "aaa.difference_update([0, 5])\n",
    "minor_label = random.sample(aaa, 4)\n",
    "print(minor_label)\n",
    "aaa.difference_update(minor_label)\n",
    "aaa = list(aaa)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
