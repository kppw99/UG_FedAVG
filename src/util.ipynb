{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a0bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7d0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_and_shuffle_labels(y_data, seed):\n",
    "    num_of_class = len(set(y_data.tolist()))\n",
    "    y_data=pd.DataFrame(y_data, columns=['label'])\n",
    "    y_data['index'] = np.arange(len(y_data))\n",
    "    label_dict = dict()\n",
    "    cur_idx = list()\n",
    "\n",
    "    for i in range(num_of_class):\n",
    "        var_name = 'label' + str(i)\n",
    "        label_info = y_data[y_data['label'] == i]\n",
    "        np.random.seed(seed)\n",
    "        label_info = np.random.permutation(label_info)\n",
    "        label_info = pd.DataFrame(label_info, columns=['label', 'index'])\n",
    "        label_dict.update({var_name: label_info })\n",
    "        cur_idx.append(0)\n",
    "\n",
    "    return label_dict, cur_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab6d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_iid_subsamples_indices(y_data, number_of_samples, seed):\n",
    "    num_of_class = len(set(y_data.tolist()))\n",
    "    label_dict, cur_idx = _split_and_shuffle_labels(y_data, seed)\n",
    "    sample_dict = dict()\n",
    "    dist = 1.0 / num_of_class\n",
    "    for i in range(number_of_samples):\n",
    "        sample_name = 'sample' + str(i)\n",
    "        dumb = pd.DataFrame()\n",
    "        for j in range(num_of_class):\n",
    "            label_name = str('label') + str(j)\n",
    "            if i == (number_of_samples - 1):\n",
    "                next_idx = len(label_dict[label_name])\n",
    "            else:\n",
    "                next_idx = int(len(label_dict[label_name]) * dist)\n",
    "                next_idx += cur_idx[j]\n",
    "            temp = label_dict[label_name][cur_idx[j]:next_idx]\n",
    "            dumb=pd.concat([dumb, temp], axis=0)\n",
    "            cur_idx[j] = next_idx\n",
    "        dumb.reset_index(drop=True, inplace=True)    \n",
    "        sample_dict.update({sample_name: dumb}) \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebcaad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_non_iid_subsamples_indices(y_data, number_of_samples, pdist, seed):    \n",
    "    num_of_class = len(set(y_data.tolist()))\n",
    "    label_dict, cur_idx = _split_and_shuffle_labels(y_data, seed)\n",
    "    sample_dict = dict()\n",
    "    for i in range(number_of_samples):\n",
    "        sample_name = 'sample' + str(i)\n",
    "        dumb = pd.DataFrame()\n",
    "        dist1 = pdist * (2 / 3)\n",
    "        dist2 = pdist - dist1\n",
    "        dist3 = (1.0 - pdist) / (num_of_class - 2)\n",
    "        for j in range(num_of_class):\n",
    "            label_name = str('label') + str(j)\n",
    "            dist = dist1 if j == i else dist2 if (j % 5) == (i % 5) else dist3\n",
    "            if i == (number_of_samples - 1):\n",
    "                next_idx = len(label_dict[label_name])\n",
    "            else:\n",
    "                next_idx = int(len(label_dict[label_name]) * dist)\n",
    "                next_idx += cur_idx[j]\n",
    "            temp = label_dict[label_name][cur_idx[j]:next_idx]\n",
    "            dumb = pd.concat([dumb, temp], axis=0)\n",
    "            cur_idx[j] = next_idx\n",
    "        dumb.reset_index(drop=True, inplace=True)    \n",
    "        sample_dict.update({sample_name: dumb}) \n",
    "    return sample_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56881cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_subsamples(sample_dict, x_data, y_data, x_name, y_name):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        indices=np.sort(np.array(sample_dict[sample_name]['index']))\n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c7e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict):\n",
    "    sum = 0\n",
    "    print('[*] Train Dataset (x, y)')\n",
    "    for idx, (x_key, y_key) in enumerate(zip(x_train_dict, y_train_dict)):\n",
    "        sum += len(x_train_dict[x_key])\n",
    "        print('- sample{}: {}, {}'.format(idx, len(x_train_dict[x_key]), len(y_train_dict[y_key])))\n",
    "        print(': ', end='')\n",
    "        for i in range(10):\n",
    "            print(y_train_dict[y_key].tolist().count(i), end=' ')\n",
    "        print('')\n",
    "    print('# total:', sum, end='\\n\\n')\n",
    "\n",
    "    sum = 0\n",
    "    print('[*] Test Dataset (x, y)')\n",
    "    for idx, (x_key, y_key) in enumerate(zip(x_test_dict, y_test_dict)):\n",
    "        sum += len(x_test_dict[x_key])\n",
    "        print('- sample{}: {}, {}'.format(idx, len(x_test_dict[x_key]), len(y_test_dict[y_key])))\n",
    "        print(': ', end='')\n",
    "        for i in range(10):\n",
    "            print(y_test_dict[y_key].tolist().count(i), end=' ')\n",
    "        print('')\n",
    "    print('# total:', sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70422cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(path='./data/mnist.pkl.gz', torch_tensor=True):\n",
    "    data_path = Path(path)\n",
    "    with gzip.open(data_path, \"rb\") as f:\n",
    "        ((x_train, y_train), (x_test, y_test)) = pickle.load(f)\n",
    "        \n",
    "    if torch_tensor:\n",
    "        x_train, y_train, x_test, y_test = map(torch.tensor, (x_train, y_train, x_test, y_test))\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51db3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_iid_samples(x_train, y_train, x_test, y_test, num_of_sample=10, pdist=0.6, seed=1, verbose=True):\n",
    "    sample_dict_train = _get_non_iid_subsamples_indices(y_train, num_of_sample, pdist, seed)\n",
    "    x_train_dict, y_train_dict = _create_subsamples(sample_dict_train, x_train, y_train, 'x_train', 'y_train')\n",
    "    \n",
    "    sample_dict_test = _get_non_iid_subsamples_indices(y_test, num_of_sample, pdist, seed)\n",
    "    x_test_dict, y_test_dict = _create_subsamples(sample_dict_test, x_test, y_test, 'x_test', 'y_test')\n",
    "    \n",
    "    if verbose:\n",
    "        _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict)\n",
    "    return x_train_dict, y_train_dict, x_test_dict, y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a150855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iid_samples(x_train, y_train, x_test, y_test, num_of_sample=10, seed=1, verbose=True):\n",
    "    sample_dict_train = _get_iid_subsamples_indices(y_train, num_of_sample, seed)\n",
    "    x_train_dict, y_train_dict = _create_subsamples(sample_dict_train, x_train, y_train, 'x_train', 'y_train')\n",
    "    \n",
    "    sample_dict_test = _get_iid_subsamples_indices(y_test, num_of_sample, seed)\n",
    "    x_test_dict, y_test_dict = _create_subsamples(sample_dict_test, x_test, y_test, 'x_test', 'y_test')\n",
    "    \n",
    "    if verbose:\n",
    "        _print_dict(x_train_dict, y_train_dict, x_test_dict, y_test_dict)\n",
    "    return x_train_dict, y_train_dict, x_test_dict, y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "217b9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(x_train, y_train, x_test, y_test, batch_size):\n",
    "    train_data = None\n",
    "    test_data = None\n",
    "    \n",
    "    if x_train != None and y_train != None:\n",
    "        train_data = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    if x_test != None and y_test != None:\n",
    "        test_data = DataLoader(TensorDataset(x_test, y_test), batch_size=1)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bf43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec67222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba81d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d383c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federate",
   "language": "python",
   "name": "federate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
